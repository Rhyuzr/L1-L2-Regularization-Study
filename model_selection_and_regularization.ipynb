{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d17efba-6067-4ee3-8721-8c5973c1c335",
      "metadata": {
        "id": "5d17efba-6067-4ee3-8721-8c5973c1c335"
      },
      "source": [
        "# Learning to do Model Selection\n",
        "In this lab, you will learn how to do model selection while strenghtening your knowledge about regularization. For this purpose, we will be using the [Digits Dataset](https://scikit-learn.org/1.5/auto_examples/datasets/plot_digits_last_image.html) embedded within scikit-learn.\n",
        "\n",
        "The goal is to train a classifier to discriminate between small digits (0 -4) and large digits (5-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62a9dad1-c1b8-471d-9813-0cf7b52ebdca",
      "metadata": {
        "id": "62a9dad1-c1b8-471d-9813-0cf7b52ebdca"
      },
      "outputs": [],
      "source": [
        "# Loading the necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c328c6aa-aead-403b-a489-ba696dce6dc4",
      "metadata": {
        "id": "c328c6aa-aead-403b-a489-ba696dce6dc4"
      },
      "source": [
        "## Loading the digits dataset and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38eace60-86ec-4165-80cd-40e436136b53",
      "metadata": {
        "id": "38eace60-86ec-4165-80cd-40e436136b53"
      },
      "outputs": [],
      "source": [
        "X, y = datasets.load_digits(return_X_y=True)\n",
        "X = StandardScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5918abbc-1b9d-42bd-be3f-8c1dc5e3495a",
      "metadata": {
        "id": "5918abbc-1b9d-42bd-be3f-8c1dc5e3495a"
      },
      "source": [
        "In the previous cell, we have loaded the digits dataset, followed by scaling the features of the input samples. Answer the following questions:\n",
        "\n",
        "1. How many samples does the dataset have?\n",
        "2. How many different values in y are there?\n",
        "3. Investigate why we scale the features and what type of scaling does StandardScaler performs.\n",
        "\n",
        "Use the cell below to implement the code to answer questions 1 and 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdb49cd-3a42-40d5-963a-cf7bbb43dfb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fdb49cd-3a42-40d5-963a-cf7bbb43dfb5",
        "outputId": "665bbaa1-b055-4711-ff0c-ba194e6c15df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the dataset: 1797\n",
            "Number of different values in y: 10\n"
          ]
        }
      ],
      "source": [
        "# Question 1: Number of samples\n",
        "num_samples = len(X)\n",
        "\n",
        "# Question 2: Number of unique values in y\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "print(f\"Number of samples in the dataset: {num_samples}\")\n",
        "print(f\"Number of different values in y: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.\n",
        "\n",
        "\n",
        "Scaling ensures that all features **contribute equally** to the model by standardizing their range, **preventing features with larger values from dominating**.\n",
        "\n",
        "*StandardScaler* standardizes features by subtracting the mean and dividing by the standard deviation, resulting in data with a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "standardScaler(x)= (x-μ)/σ"
      ],
      "metadata": {
        "id": "ktKTr6KAIH0j"
      },
      "id": "ktKTr6KAIH0j"
    },
    {
      "cell_type": "markdown",
      "id": "6d7e9b05-4caa-4675-9367-a54bcb0dd13c",
      "metadata": {
        "id": "6d7e9b05-4caa-4675-9367-a54bcb0dd13c"
      },
      "source": [
        "Using the original labels, create new labels (y_new) that reflects the classification problem we want to solve: discriminate between small and large digits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1ba45f-123f-452e-a3d0-7bb9793062c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1ba45f-123f-452e-a3d0-7bb9793062c6",
        "outputId": "6ecd7606-54af-4b9f-d2a8-ba9e2e177c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1437\n",
            "Testing set size: 360\n"
          ]
        }
      ],
      "source": [
        "# classify small against large digits\n",
        "\n",
        "def classify_digit(digit):\n",
        "    return 0 if digit <= 4 else 1\n",
        "\n",
        "y_new = np.array([classify_digit(d) for d in y])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Testing set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479e37ce-2211-428a-8cd4-ecfe30ed7ade",
      "metadata": {
        "id": "479e37ce-2211-428a-8cd4-ecfe30ed7ade"
      },
      "source": [
        "We now split the data into training and testing. We will leave 20% of the data for testing.\n",
        "\n",
        "**Question:** What property of a model is measure with the testing set?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6e3abd-178e-4a08-a240-1905a13c26d9",
      "metadata": {
        "id": "0a6e3abd-178e-4a08-a240-1905a13c26d9"
      },
      "source": [
        "Your answer: The testing set measures the generalization ability of a model — how well the model performs on unseen data. This is a critical evaluation metric to ensure the model isn't overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10190e20-44b8-4b0e-a7fd-a033d3235805",
      "metadata": {
        "id": "10190e20-44b8-4b0e-a7fd-a033d3235805"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46b5ce13-4658-4784-b036-4af800317710",
      "metadata": {
        "id": "46b5ce13-4658-4784-b036-4af800317710"
      },
      "source": [
        "We will use logistic regression with regularization to solve our classification problem. In a first experiment, we will use 'L2' regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18780d5e-e286-4912-96c4-c54763b54764",
      "metadata": {
        "id": "18780d5e-e286-4912-96c4-c54763b54764"
      },
      "outputs": [],
      "source": [
        "model_l2 = LogisticRegression(penalty=\"l2\", tol=0.01, solver=\"saga\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ce1da2-1bd5-47d9-9216-68b876323b92",
      "metadata": {
        "id": "b8ce1da2-1bd5-47d9-9216-68b876323b92"
      },
      "source": [
        "Use the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to understand the role of each parameter. Provide your answer below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb43d85-ffc7-4cb2-8f61-4820abeaec94",
      "metadata": {
        "id": "2bb43d85-ffc7-4cb2-8f61-4820abeaec94"
      },
      "source": [
        "**penalty:**\n",
        "\n",
        "Specifies the regularization technique used to prevent overfitting by adding a penalty term to the loss function.\n",
        "\"l2\" means Ridge regularization, which penalizes large weights by adding the squared sum of coefficients to the cost function.\n",
        "\n",
        "**tol:**\n",
        "\n",
        "The tolerance for the optimization algorithm. It determines the stopping criteria.\n",
        "Smaller values result in more precise optimization but increase computational cost.\n",
        "\n",
        "**solver:**\n",
        "\n",
        "Specifies the algorithm used for optimization.\n",
        "\"saga\" is a fast and robust solver that supports both l1 and l2 regularization and works well with large datasets and sparse data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a07556a-94dc-4e0d-b9e2-7fc6d95ff579",
      "metadata": {
        "id": "1a07556a-94dc-4e0d-b9e2-7fc6d95ff579"
      },
      "source": [
        "Your task will be to choose the best regularization hyperparameter ($\\lambda$ in the course), i.e. do model selection."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fef1b1f-9189-4822-84e6-56b8b0644fe1",
      "metadata": {
        "id": "7fef1b1f-9189-4822-84e6-56b8b0644fe1"
      },
      "source": [
        "Define a vector lambda_values with a range of hyper-parameters to evaluate. Consider, at the least, the following values: 0.001, 0.01, 0.1, 1, 10, 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdcd9939-46c5-4322-b81b-7450d5740e59",
      "metadata": {
        "id": "fdcd9939-46c5-4322-b81b-7450d5740e59"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for lambda\n",
        "\n",
        "lambda_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "param_grid = {'C': [1 / l for l in lambda_values]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0d8eb8-8121-4ef2-b44a-44f1e6e974fe",
      "metadata": {
        "id": "8c0d8eb8-8121-4ef2-b44a-44f1e6e974fe"
      },
      "source": [
        "**Important:** Scikit-learn uses the hyper-parameter C for the regularization. This is equivalent to C=1/lambda, where lambda is the expression seen in the course."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc49b73-6ac6-4bf4-8ebb-ae3a8ecfa0d4",
      "metadata": {
        "id": "9bc49b73-6ac6-4bf4-8ebb-ae3a8ecfa0d4"
      },
      "source": [
        "To choose the right value, you will do cross-validation with the available training dataset.\n",
        "\n",
        "**Question:** According to the slides you reviewed, what is a typical value for K in K-fold cross-validation?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb3e2649-e8ac-4571-8a5a-e7810a67207d",
      "metadata": {
        "id": "bb3e2649-e8ac-4571-8a5a-e7810a67207d"
      },
      "source": [
        " A typical value for K in K-fold cross-validation is 5 as these values strike a balance between computational efficiency and reliable model evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc046a56-4d0c-40fe-ba4d-70e4bf739d35",
      "metadata": {
        "id": "fc046a56-4d0c-40fe-ba4d-70e4bf739d35"
      },
      "source": [
        "Use that value to initialize the KFold class below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a67aeed-26d0-4dd1-9ddf-b2d65b044e27",
      "metadata": {
        "id": "1a67aeed-26d0-4dd1-9ddf-b2d65b044e27"
      },
      "outputs": [],
      "source": [
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902ab34a-6fcf-4497-a4c7-a1e9c7fb7bcf",
      "metadata": {
        "id": "902ab34a-6fcf-4497-a4c7-a1e9c7fb7bcf"
      },
      "source": [
        "You will evaluate over K folds each of the models corresponding to the hyperparameters defined in lambda_grid.\n",
        "\n",
        "**Your task:** Comment every line of code that has not been commented in the code snippet below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8775a47-3171-4680-9fce-805d87a0f074",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8775a47-3171-4680-9fce-805d87a0f074",
        "outputId": "94ff9de9-f695-4291-ac56-6919b204686d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now testing for lambda:  1000.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8854166666666666\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9198606271777003\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8865514905149052\n",
            "Now testing for lambda:  100.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8854166666666666\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9198606271777003\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8865514905149052\n",
            "Now testing for lambda:  10.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8854166666666666\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9198606271777003\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8865514905149052\n",
            "Now testing for lambda:  1.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8854166666666666\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9198606271777003\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8865514905149052\n",
            "Now testing for lambda:  0.1\n",
            "accuracy: 0.9097222222222222\n",
            "accuracy: 0.8923611111111112\n",
            "accuracy: 0.8501742160278746\n",
            "accuracy: 0.9233449477351916\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8865490708478513\n",
            "Now testing for lambda:  0.01\n",
            "accuracy: 0.90625\n",
            "accuracy: 0.8784722222222222\n",
            "accuracy: 0.8362369337979094\n",
            "accuracy: 0.9059233449477352\n",
            "accuracy: 0.8466898954703833\n",
            "average of fold 0.8747144792876501\n"
          ]
        }
      ],
      "source": [
        "accuracy_scores = [] # Initialize a list to store accuracy scores for each C value\n",
        "\n",
        "for a_lambda in param_grid['C']: # Perform cross-validation for each value of C in the grid\n",
        "    print('Now testing for lambda: ', a_lambda)\n",
        "    C = a_lambda # Scikit-learn's regularization hyperparameter is equivalent to 1/lambda from the course.\n",
        "    model_l2.set_params(C=C) # Update the model's C parameter for the current lambda\n",
        "    fold_accuracies = [] # Stores the accuracy of the trained model for each fold\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train): # Split the training data into K folds\n",
        "        X_ttrain, X_val = X_train[train_index], X_train[val_index] # Extract the training and validation data for the current fold\n",
        "        y_ttrain, y_val = y_train[train_index], y_train[val_index] # Extract the corresponding labels for the current fold\n",
        "\n",
        "        model_l2.fit(X_ttrain, y_ttrain) # Train the model on the training data of the current fold\n",
        "        y_pred = model_l2.predict(X_val) # Predict the labels on the validation data\n",
        "        accuracy = accuracy_score(y_val, y_pred) # Calculate the accuracy of the model on the validation set\n",
        "        print('accuracy:', accuracy) # Print the accuracy for the current fold\n",
        "        fold_accuracies.append(accuracy) # Append the accuracy to the list of fold accuracies\n",
        "\n",
        "    average_accuracy = sum(fold_accuracies) / num_folds # Calculate the average accuracy over all folds\n",
        "    print('average of fold', average_accuracy) # Print the average accuracy for the current lambda\n",
        "    accuracy_scores.append(average_accuracy) # Append the average accuracy to the list of accuracy scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95fed62b-a801-4a7d-81d9-ca31760c349d",
      "metadata": {
        "id": "95fed62b-a801-4a7d-81d9-ca31760c349d"
      },
      "source": [
        "Using the vector accuracy_scores, determine which value of lambda leads to the best model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c7505e5-95e5-478e-ba9e-ba701169d134",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "7c7505e5-95e5-478e-ba9e-ba701169d134",
        "outputId": "55a5cfda-c3f0-41d2-b4d1-e988920e9696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best lambda: 1000.0\n",
            "Best accuracy: 0.8865514905149052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1000.0, solver='saga', tol=0.01)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000.0, solver=&#x27;saga&#x27;, tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1000.0, solver=&#x27;saga&#x27;, tol=0.01)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Find the best lambda value\n",
        "best_lambda_l2 = param_grid['C'][np.argmax(accuracy_scores)]\n",
        "best_accuracy_l2 = max(accuracy_scores)\n",
        "\n",
        "print(\"Best lambda:\", best_lambda_l2)\n",
        "print(\"Best accuracy:\", best_accuracy_l2)\n",
        "\n",
        "# Train the final model with the best lambda parameter\n",
        "best_model_l2 = LogisticRegression(C=best_lambda_l2, penalty=\"l2\", tol=0.01, solver=\"saga\")\n",
        "best_model_l2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value of lambda that leads to the best model is 100."
      ],
      "metadata": {
        "id": "S4_kWyfaI7oR"
      },
      "id": "S4_kWyfaI7oR"
    },
    {
      "cell_type": "markdown",
      "id": "2cfbcdc4-171c-4f57-a059-68d781bae3e3",
      "metadata": {
        "id": "2cfbcdc4-171c-4f57-a059-68d781bae3e3"
      },
      "source": [
        "Using the chosen model, check its generalization error using the test set. Print the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7651948f-3688-44ab-828d-0d5630b4f11d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7651948f-3688-44ab-828d-0d5630b4f11d",
        "outputId": "96b7147b-5617-4a0a-e8dd-4574d87ca4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9138888888888889\n"
          ]
        }
      ],
      "source": [
        "y_pred = best_model_l2.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d4e81f-8b6b-48c4-8d4f-39d6308b639a",
      "metadata": {
        "id": "76d4e81f-8b6b-48c4-8d4f-39d6308b639a"
      },
      "source": [
        "### L1 regularization\n",
        "Now, we will do a similar exercise using Logistic Regression with L1 regularization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b9ea257-0ea3-4185-a7ed-71a6bb808831",
      "metadata": {
        "id": "4b9ea257-0ea3-4185-a7ed-71a6bb808831"
      },
      "outputs": [],
      "source": [
        "model_l1 = LogisticRegression(penalty=\"l1\", tol=0.01, solver=\"saga\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ed0852-8395-4691-9cda-f0f5ada4ecae",
      "metadata": {
        "id": "b5ed0852-8395-4691-9cda-f0f5ada4ecae"
      },
      "source": [
        "Use the code used to cross-validate Logistic regression with L2 regularization and choose the best model, do the same to choose the best model when using the L1 regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b94a4e08-a6ba-4dbc-a832-5318d7459f54",
      "metadata": {
        "id": "b94a4e08-a6ba-4dbc-a832-5318d7459f54",
        "outputId": "6cf04b41-ce94-4071-b6d0-4d07a3f4f523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now testing for lambda:  1000.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8819444444444444\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9163763066202091\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8851601819589623\n",
            "Now testing for lambda:  100.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8819444444444444\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9198606271777003\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8858570460704607\n",
            "Now testing for lambda:  10.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8819444444444444\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9198606271777003\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8858570460704607\n",
            "Now testing for lambda:  1.0\n",
            "accuracy: 0.9131944444444444\n",
            "accuracy: 0.8854166666666666\n",
            "accuracy: 0.8571428571428571\n",
            "accuracy: 0.9163763066202091\n",
            "accuracy: 0.8571428571428571\n",
            "average of fold 0.8858546264034068\n",
            "Now testing for lambda:  0.1\n",
            "accuracy: 0.8888888888888888\n",
            "accuracy: 0.8819444444444444\n",
            "accuracy: 0.8536585365853658\n",
            "accuracy: 0.9024390243902439\n",
            "accuracy: 0.8536585365853658\n",
            "average of fold 0.8761178861788619\n",
            "Now testing for lambda:  0.01\n",
            "accuracy: 0.84375\n",
            "accuracy: 0.8680555555555556\n",
            "accuracy: 0.8118466898954704\n",
            "accuracy: 0.8292682926829268\n",
            "accuracy: 0.7839721254355401\n",
            "average of fold 0.8273785327138985\n",
            "Best lambda for L1 regularization: 100.0\n",
            "Best accuracy for L1 regularization: 0.8858570460704607\n",
            "Final Accuracy for L1 regularization:  0.9138888888888889\n"
          ]
        }
      ],
      "source": [
        "accuracy_scores = [] # Reinitialize the list to store accuracy scores for L1\n",
        "\n",
        "for a_lambda in param_grid['C']: # Perform cross-validation for each value of C in the grid\n",
        "    print('Now testing for lambda: ', a_lambda)\n",
        "    C = a_lambda # Scikit-learn's regularization hyperparameter is equivalent to 1/lambda from the course.\n",
        "    model_l1.set_params(C=C) # Update the model's C parameter for the current lambda\n",
        "    fold_accuracies = [] # Stores the accuracy of the trained model for each fold\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train): # Split the training data into K folds\n",
        "        X_ttrain, X_val = X_train[train_index], X_train[val_index] # Extract the training and validation data for the current fold\n",
        "        y_ttrain, y_val = y_train[train_index], y_train[val_index] # Extract the corresponding labels for the current fold\n",
        "\n",
        "        model_l1.fit(X_ttrain, y_ttrain) # Train the model on the training data of the current fold\n",
        "        y_pred = model_l1.predict(X_val) # Predict the labels on the validation data\n",
        "        accuracy = accuracy_score(y_val, y_pred) # Calculate the accuracy of the model on the validation set\n",
        "        print('accuracy:', accuracy) # Print the accuracy for the current fold\n",
        "        fold_accuracies.append(accuracy) # Append the accuracy to the list of fold accuracies\n",
        "\n",
        "    average_accuracy = sum(fold_accuracies) / num_folds # Calculate the average accuracy over all folds\n",
        "    print('average of fold', average_accuracy) # Print the average accuracy for the current lambda\n",
        "    accuracy_scores.append(average_accuracy) # Append the average accuracy to the list of accuracy scores\n",
        "\n",
        "# Find the best lambda value for L1 regularization\n",
        "best_lambda_l1 = param_grid['C'][np.argmax(accuracy_scores)]\n",
        "best_accuracy_l1 = max(accuracy_scores)\n",
        "print(\"Best lambda for L1 regularization:\", best_lambda_l1)\n",
        "print(\"Best accuracy for L1 regularization:\", best_accuracy_l1)\n",
        "\n",
        "# Train the final model with the best lambda parameter for L1 regularization\n",
        "best_model_l1 = LogisticRegression(C=best_lambda_l1, penalty=\"l1\", tol=0.01, solver=\"saga\")\n",
        "best_model_l1.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the final L1 model on the test set\n",
        "y_pred = best_model_l1.predict(X_test)\n",
        "final_accuracy_l1 = accuracy_score(y_test, y_pred)\n",
        "print(\"Final Accuracy for L1 regularization: \", final_accuracy_l1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57859154-2560-4a19-a6a5-81620d57c783",
      "metadata": {
        "id": "57859154-2560-4a19-a6a5-81620d57c783"
      },
      "source": [
        "**Important:** You should not use the generalization performance of each of the models (L1 vs L2) to do a choice among them. You would need a cross-validation procedure for that matter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e5abd9-63fa-453a-a996-6741724e57d7",
      "metadata": {
        "id": "82e5abd9-63fa-453a-a996-6741724e57d7"
      },
      "source": [
        "## Comparing the properties of each regularization strategy\n",
        "We will now use the full training set to study some of the properties of each regularization strategy.\n",
        "\n",
        "In the code snippet below, you will be training 3 different models per regularization strategy and observing how these affect the weights of the model.\n",
        "\n",
        "**Your task:** Comment the lines of code that do not have any comments.\n",
        "\n",
        "As a reminder, the parameter C in scikit-learn is equivalent to C=1/lambda, where lambda is the regularization hyperparameter as seen in the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e7291383-327c-4cf7-834c-e655d9406852",
      "metadata": {
        "id": "e7291383-327c-4cf7-834c-e655d9406852",
        "outputId": "829182cd-7645-4c17-de11-9e8a776aa456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=1.00\n",
            "Sparsity with L1 penalty:                6.25%\n",
            "Sparsity with L2 penalty:                4.69%\n",
            "Score with L1 penalty:                   0.10\n",
            "Score with L2 penalty:                   0.10\n",
            "C=0.10\n",
            "Sparsity with L1 penalty:                32.81%\n",
            "Sparsity with L2 penalty:                4.69%\n",
            "Score with L1 penalty:                   0.10\n",
            "Score with L2 penalty:                   0.10\n",
            "C=0.01\n",
            "Sparsity with L1 penalty:                85.94%\n",
            "Sparsity with L2 penalty:                4.69%\n",
            "Score with L1 penalty:                   0.10\n",
            "Score with L2 penalty:                   0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, axes = plt.subplots(3, 2) # Create a subplot grid with 3 rows and 2 columns\n",
        "\n",
        "# Set regularization parameter\n",
        "for i, (C, axes_row) in enumerate(zip((1, 0.1, 0.01), axes)): # Loop over different values of the regularization parameter C\n",
        "    # Increase tolerance for short training time\n",
        "    model_l1 = LogisticRegression(C=C, penalty=\"l1\", tol=0.01, solver=\"saga\") # Initialize Logistic Regression with L1 penalty\n",
        "    model_l2 = LogisticRegression(C=C, penalty=\"l2\", tol=0.01, solver=\"saga\") # Initialize Logistic Regression with L2 penalty\n",
        "\n",
        "    model_l1.fit(X_train, y_train) # Fit the L1-penalized model on the training data\n",
        "    model_l2.fit(X_train, y_train) # Fit the L2-penalized model on the training data\n",
        "\n",
        "    coef_l1_LR = model_l1.coef_.ravel() # Extract and flatten the coefficients for the L1 model\n",
        "    coef_l2_LR = model_l2.coef_.ravel() # Extract and flatten the coefficients for the L2 model\n",
        "\n",
        "    # coef_l1_LR contains zeros due to the\n",
        "    # L1 sparsity inducing norm\n",
        "\n",
        "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100 # Calculate the percentage of zero coefficients for the L1 model\n",
        "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100 # Calculate the percentage of zero coefficients for the L2 model\n",
        "\n",
        "    #DO NOT COMMENT THE LINES BELOW\n",
        "    print(f\"C={C:.2f}\")\n",
        "    print(f\"{'Sparsity with L1 penalty:':<40} {sparsity_l1_LR:.2f}%\")\n",
        "    print(f\"{'Sparsity with L2 penalty:':<40} {sparsity_l2_LR:.2f}%\")\n",
        "    print(f\"{'Score with L1 penalty:':<40} {model_l1.score(X, y):.2f}\")\n",
        "    print(f\"{'Score with L2 penalty:':<40} {model_l2.score(X, y):.2f}\")\n",
        "\n",
        "    if i == 0: # Set titles for the first row of subplots\n",
        "        axes_row[0].set_title(\"L1 penalty\")\n",
        "        axes_row[1].set_title(\"L2 penalty\")\n",
        "\n",
        "    for ax, coefs in zip(axes_row, [coef_l1_LR, coef_l2_LR]): # Loop through the axes and coefficients for visualization\n",
        "        ax.imshow(\n",
        "            np.abs(coefs.reshape(8, 8)), # Reshape and visualize the coefficients as an 8x8 grid\n",
        "            interpolation=\"nearest\", # Set interpolation for better visualization\n",
        "            cmap=\"binary\", # Use a binary color map\n",
        "            vmax=1, # Set the maximum value for the color scale\n",
        "            vmin=0, # Set the minimum value for the color scale\n",
        "        )\n",
        "        ax.set_xticks(()) # Remove x-axis ticks\n",
        "        ax.set_yticks(()) # Remove y-axis ticks\n",
        "\n",
        "    axes_row[0].set_ylabel(f\"C = {C}\") # Label the rows with the value of C\n",
        "\n",
        "plt.show() # Display the plot\n",
        "\n",
        "\n",
        "#Note: This code example has been adapted from scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de0617db-f100-4c69-af15-ce2c795d6d5e",
      "metadata": {
        "id": "de0617db-f100-4c69-af15-ce2c795d6d5e"
      },
      "source": [
        "**Question:** Explain the differences between L1 and L2 regularization at the light of the observed plots. What are the obtained results saying?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a57c19-5df5-4031-91d1-304f08936bf3",
      "metadata": {
        "id": "f1a57c19-5df5-4031-91d1-304f08936bf3"
      },
      "source": [
        "L1 regularization induces high sparsity, meaning more coefficients are set to zero as the regularization strength (C) decreases, with values ranging from 6.25% to 85.94%. In contrast, L2 regularization (Ridge) maintains a constant sparsity of 4.69% regardless of C, as it doesn't set coefficients to zero but shrinks them.\n",
        "\n",
        "Despite these differences in sparsity, the model performance (score) remains the same (0.10) for both L1 and L2 regularization, suggesting that sparsity does not impact performance significantly in this case."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
